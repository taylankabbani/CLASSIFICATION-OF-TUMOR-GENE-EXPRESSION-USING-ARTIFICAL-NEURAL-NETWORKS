---
title: "second-run-with-all-cancer"
author: "Taylan Kabbani"
date: "March 27, 2018"
output:
  html_document:
    df_print: paged
---

This .Rmd file is prepared by taking the reference of `first-run.Rmd` who prepared by Alper Yilmaz.


```{r}
library(tidyverse)
library(keras)

all_cancer_types <- readRDS("all_cancer_types.rds")
```


# Preparing input data

Refer to `all_cancer_types.Rmd` file for how B.Darendeli selected 784 genes (saved as `all_cancer_types.rds`). 

```{r}
all_cancer_log_normalized <- readRDS("all_cancer_log_normalized.rds")
no_of_samples <- ncol(all_cancer_log_normalized) - 1
v_all <- all_cancer_log_normalized %>% 
  #gather(sample, value, -gene) %>% 
  #mutate(value =ifelse(value < 1, 1, value)) %>% 
  #separate(sample, c("patient", "case", "stage"), sep="_") %>% 
  #mutate(log_value = log(value)) %>% 
  #select(-value) %>% 
  #spread(sample, log_value) %>%          
  select(-gene) %>%
  as.matrix(byrow = TRUE) %>% 
  { colnames(.) ->> sample_names      # ugly hack to save intermediate https://stackoverflow.com/a/47879695/4579196
    dim(.) <- c(28,28,no_of_samples)  # changing dimensions of matrix and printing again
    .                                 # so that pipe is not broken: https://stackoverflow.com/a/44052271/4579196
  } %>% 
  aperm(c(3,1,2))
```

Check size of the final 3d array. Its dimensions should be no_of_samples, 28 , 28

```{r}
dim(v_all)  # should be no_of_samples, 28 , 28
# d[1,1:28,1:28] should print data for first patient
```

Finally, use `array_reshape()` from `keras` package to reshape the data to be used as input layer.

```{r}
input <- array_reshape(v_all, c(no_of_samples, 28, 28, 1))
```

# Preparing labels array

`sample_names` object kept from previous step is used to convert sample names into 0 or 1. If sample name contains "normal" then it's assigned 0, other labels, such as "Tumor" or "Metastatic" are assigned 1.

A 1d array, `labels` , holds the labels. And the distribution of labels is;

```{r}
labels <- sample_names %>% 
  as_data_frame() %>% 
  filter(value !="gene") %>% 
  # Normal=0, Tumor or Metastatic=1
  mutate(label= ifelse(grepl("Normal",value), 0, 1))  %T>%  # tee-operator
  { count(., label) %>% print() }  %>%   # count values - an ugly hack
  pull(label) %>% 
  array()
```

Check size of array. Should be 1d array as long as `no_of_samples`

```{r}
# class(labels)
dim(labels)
```

# Starting to run Keras

The code from [Rstudio Keras MNIST CNN example](https://keras.rstudio.com/articles/examples/mnist_cnn.html) is modified for our own sample

```{r}
batch_size <- 128
num_classes <- 2
epochs <- 12

img_rows <- 28
img_cols <- 28

# The data, shuffled and split between train and test sets
x_train <- input
y_train <- labels
#x_test <- mnist$test$x
#y_test <- mnist$test$y

# Redefine  dimension of train/test inputs

#we already did the arrat_reshape part above
#x_train <- array_reshape(x_train, c(nrow(x_train), img_rows, img_cols, 1))
input_shape <- c(img_rows, img_cols, 1)

# Transform RGB values into [0,1] range
#x_train <- x_train / 255
#x_test <- x_test / 255

cat('x_train_shape:', dim(x_train), '\n')
cat(nrow(x_train), 'train samples\n')
#cat(nrow(x_test), 'test samples\n')

# Convert class vectors to binary class matrices
y_train <- to_categorical(y_train, num_classes)
#y_test <- to_categorical(y_test, num_classes)

# Define Model -----------------------------------------------------------

# Define model
model <- keras_model_sequential() %>%
  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu',
                input_shape = input_shape) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu') %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_dropout(rate = 0.25) %>% 
  layer_flatten() %>% 
  layer_dense(units = 128, activation = 'relu') %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = num_classes, activation = 'softmax')

# Compile model
model %>% compile(
  loss = loss_categorical_crossentropy,
  optimizer = optimizer_adadelta(),
  metrics = c('accuracy')
)
```


```{r}
# Train model
model %>% fit(
  x_train, y_train,
  batch_size = batch_size,
  epochs = epochs,
  validation_split = 0.2
)
```

```{r}

```

